{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽŒ Kintsugi AI - Digital Image Restoration\n",
    "\n",
    "This notebook trains a U-Net model with attention gates for restoring damaged historical images.\n",
    "\n",
    "**Features:**\n",
    "- Synthetic degradation pipeline (scratches, noise, masks, fading)\n",
    "- Attention U-Net architecture\n",
    "- Composite loss (L1 + SSIM + Perceptual)\n",
    "- Progressive training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Kintsugi AI repository\n",
    "!git clone https://github.com/AleenaTahir1/Kintsugi-AI.git\n",
    "%cd Kintsugi-AI\n",
    "\n",
    "import os\n",
    "PROJECT_ROOT = '/content/Kintsugi-AI'\n",
    "\n",
    "# Create data directories\n",
    "os.makedirs(f'{PROJECT_ROOT}/data/train', exist_ok=True)\n",
    "os.makedirs(f'{PROJECT_ROOT}/data/val', exist_ok=True)\n",
    "os.makedirs(f'{PROJECT_ROOT}/checkpoints', exist_ok=True)\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q opencv-python Pillow tqdm gradio matplotlib gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify PyTorch and CUDA\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Dataset\n",
    "\n",
    "We'll use CelebA-HQ for face restoration. You can also use your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Download CelebA-HQ subset (recommended for quick training)\n",
    "# This downloads a smaller subset for demonstration\n",
    "\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# CelebA-HQ 256x256 subset (adjust URL to your dataset)\n",
    "# For full dataset, use Kaggle or official sources\n",
    "\n",
    "# Example: Download from Google Drive (replace with your link)\n",
    "# gdown.download('https://drive.google.com/uc?id=YOUR_FILE_ID', 'celeba_hq.zip', quiet=False)\n",
    "\n",
    "# For now, we'll use a small sample\n",
    "print(\"Please upload your dataset to /content/kintsugi-ai/data/train/\")\n",
    "print(\"Or run the cell below to use sample images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Generate sample images for testing\n",
    "# This creates random colored squares as placeholder images\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def create_sample_images(output_dir, num_images=100, size=256):\n",
    "    \"\"\"Create sample gradient images for testing.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create gradient image with random colors\n",
    "        x = np.linspace(0, 1, size)\n",
    "        y = np.linspace(0, 1, size)\n",
    "        xx, yy = np.meshgrid(x, y)\n",
    "        \n",
    "        # Random gradient direction and colors\n",
    "        angle = np.random.uniform(0, 2 * np.pi)\n",
    "        gradient = np.cos(angle) * xx + np.sin(angle) * yy\n",
    "        \n",
    "        # Create RGB channels\n",
    "        r = (gradient * np.random.uniform(100, 255)).astype(np.uint8)\n",
    "        g = ((1 - gradient) * np.random.uniform(100, 255)).astype(np.uint8)\n",
    "        b = (np.abs(gradient - 0.5) * 2 * np.random.uniform(100, 255)).astype(np.uint8)\n",
    "        \n",
    "        img = np.stack([r, g, b], axis=-1)\n",
    "        \n",
    "        # Add some patterns\n",
    "        if np.random.random() > 0.5:\n",
    "            # Add circles\n",
    "            for _ in range(np.random.randint(3, 10)):\n",
    "                cx, cy = np.random.randint(0, size, 2)\n",
    "                radius = np.random.randint(10, 50)\n",
    "                color = np.random.randint(0, 255, 3)\n",
    "                yy, xx = np.ogrid[:size, :size]\n",
    "                mask = (xx - cx) ** 2 + (yy - cy) ** 2 <= radius ** 2\n",
    "                img[mask] = color\n",
    "        \n",
    "        Image.fromarray(img).save(f\"{output_dir}/sample_{i:04d}.png\")\n",
    "    \n",
    "    print(f\"Created {num_images} sample images in {output_dir}\")\n",
    "\n",
    "# Create sample images\n",
    "create_sample_images(f'{PROJECT_ROOT}/data/train', num_images=500)\n",
    "create_sample_images(f'{PROJECT_ROOT}/data/val', num_images=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Upload from Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy your dataset from Drive\n",
    "# !cp -r /content/drive/MyDrive/your_dataset/* /content/kintsugi-ai/data/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Source Code\n",
    "\n",
    "Upload the project files or paste them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you uploaded the project as a zip\n",
    "# !unzip kintsugi-ai.zip -d /content/\n",
    "\n",
    "# Add project to path\n",
    "import sys\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "# Verify imports\n",
    "try:\n",
    "    from src.degradation import DegradationPipeline\n",
    "    from src.dataset import KintsugiDataset, ProgressiveDataLoader\n",
    "    from src.model import create_model, AttentionUNet\n",
    "    from src.losses import CompositeLoss, compute_psnr\n",
    "    from src.trainer import Trainer\n",
    "    from src.inference import Restorer\n",
    "    print(\"All modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please ensure all source files are uploaded to the project directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Degradation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load a sample image\n",
    "sample_path = f'{PROJECT_ROOT}/data/train/'\n",
    "sample_files = [f for f in os.listdir(sample_path) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "if sample_files:\n",
    "    img = cv2.imread(os.path.join(sample_path, sample_files[0]))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    # Apply degradations\n",
    "    pipeline = DegradationPipeline(severity=0.8)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    \n",
    "    axes[0, 0].imshow(img)\n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(pipeline.apply_scratches(img.copy()))\n",
    "    axes[0, 1].set_title('Scratches')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    axes[0, 2].imshow(pipeline.apply_gaussian_noise(img.copy()))\n",
    "    axes[0, 2].set_title('Gaussian Noise')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    axes[0, 3].imshow(pipeline.apply_random_mask(img.copy()))\n",
    "    axes[0, 3].set_title('Random Masks')\n",
    "    axes[0, 3].axis('off')\n",
    "    \n",
    "    axes[1, 0].imshow(pipeline.apply_color_fading(img.copy()))\n",
    "    axes[1, 0].set_title('Color Fading')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].imshow(pipeline.apply_stains(img.copy()))\n",
    "    axes[1, 1].set_title('Stains')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    axes[1, 2].imshow(pipeline.apply_folding_lines(img.copy()))\n",
    "    axes[1, 2].set_title('Folding Lines')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    # Full degradation\n",
    "    axes[1, 3].imshow(pipeline(img.copy()))\n",
    "    axes[1, 3].set_title('Combined')\n",
    "    axes[1, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{PROJECT_ROOT}/degradation_examples.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No sample images found. Please upload images first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configure Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ColabConfig:\n",
    "    # Data\n",
    "    train_dir: str = f'{PROJECT_ROOT}/data/train'\n",
    "    val_dir: str = f'{PROJECT_ROOT}/data/val'\n",
    "    image_size: int = 256\n",
    "    batch_size: int = 16  # Adjust based on GPU memory\n",
    "    num_workers: int = 2\n",
    "    \n",
    "    # Model\n",
    "    model_type: str = 'attention_unet'\n",
    "    features: list = None  # Will be set in __post_init__\n",
    "    \n",
    "    # Training\n",
    "    epochs: int = 50\n",
    "    lr: float = 2e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    use_amp: bool = True\n",
    "    \n",
    "    # Progressive training\n",
    "    progressive: bool = True\n",
    "    start_severity: float = 0.3\n",
    "    end_severity: float = 1.0\n",
    "    warmup_epochs: int = 10\n",
    "    \n",
    "    # Loss weights\n",
    "    l1_weight: float = 1.0\n",
    "    ssim_weight: float = 0.5\n",
    "    perceptual_weight: float = 0.1\n",
    "    edge_weight: float = 0.1\n",
    "    \n",
    "    # Checkpointing\n",
    "    save_dir: str = f'{PROJECT_ROOT}/checkpoints'\n",
    "    save_every: int = 5\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.features is None:\n",
    "            self.features = [64, 128, 256, 512]\n",
    "\n",
    "config = ColabConfig()\n",
    "print(\"Configuration:\")\n",
    "for key, value in vars(config).items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialize Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create datasets\n",
    "print(\"\\nLoading datasets...\")\n",
    "train_dataset = KintsugiDataset(\n",
    "    root_dir=config.train_dir,\n",
    "    image_size=config.image_size,\n",
    "    severity=config.start_severity,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "val_dataset = KintsugiDataset(\n",
    "    root_dir=config.val_dir,\n",
    "    image_size=config.image_size,\n",
    "    severity=1.0,\n",
    "    augment=False\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Val samples: {len(val_dataset)}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = ProgressiveDataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    start_severity=config.start_severity,\n",
    "    end_severity=config.end_severity,\n",
    "    warmup_epochs=config.warmup_epochs\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Create model\n",
    "print(\"\\nCreating model...\")\n",
    "model = create_model(\n",
    "    model_type=config.model_type,\n",
    "    features=config.features,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a training batch\n",
    "degraded, clean = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i in range(4):\n",
    "    # Degraded\n",
    "    img = degraded[i].permute(1, 2, 0).numpy()\n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title('Degraded')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Clean\n",
    "    img = clean[i].permute(1, 2, 0).numpy()\n",
    "    axes[1, i].imshow(img)\n",
    "    axes[1, i].set_title('Clean (Target)')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.suptitle('Training Batch: Degraded (top) vs Clean (bottom)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    "    epochs=config.epochs,\n",
    "    use_amp=config.use_amp,\n",
    "    l1_weight=config.l1_weight,\n",
    "    ssim_weight=config.ssim_weight,\n",
    "    perceptual_weight=config.perceptual_weight,\n",
    "    edge_weight=config.edge_weight,\n",
    "    save_dir=config.save_dir,\n",
    "    save_every=config.save_every\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized. Starting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train!\n",
    "history = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# PSNR\n",
    "axes[1].plot(history['val_psnr'])\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('PSNR (dB)')\n",
    "axes[1].set_title(f'Validation PSNR (Best: {max(history[\"val_psnr\"]):.2f} dB)')\n",
    "axes[1].axhline(y=25, color='r', linestyle='--', label='Target (25 dB)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "# SSIM\n",
    "axes[2].plot(history['val_ssim'])\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('SSIM')\n",
    "axes[2].set_title(f'Validation SSIM (Best: {max(history[\"val_ssim\"]):.4f})')\n",
    "axes[2].axhline(y=0.85, color='r', linestyle='--', label='Target (0.85)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{PROJECT_ROOT}/training_history.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Best PSNR: {max(history['val_psnr']):.2f} dB\")\n",
    "print(f\"  Best SSIM: {max(history['val_ssim']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "restorer = Restorer(\n",
    "    checkpoint_path=f'{config.save_dir}/best_model.pth',\n",
    "    model_type=config.model_type,\n",
    "    features=config.features,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on validation images\n",
    "from src.inference import compare_images\n",
    "\n",
    "# Get some test samples\n",
    "test_degraded, test_clean = next(iter(val_loader))\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "\n",
    "for i in range(4):\n",
    "    # Get single image\n",
    "    degraded_np = (test_degraded[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    clean_np = (test_clean[i].permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "    # Restore\n",
    "    with torch.no_grad():\n",
    "        restored = restorer.model(test_degraded[i:i+1].to(device))\n",
    "    restored_np = (restored[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "    \n",
    "    # Display\n",
    "    axes[0, i].imshow(degraded_np)\n",
    "    axes[0, i].set_title('Degraded Input')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(restored_np)\n",
    "    axes[1, i].set_title('Restored')\n",
    "    axes[1, i].axis('off')\n",
    "    \n",
    "    axes[2, i].imshow(clean_np)\n",
    "    axes[2, i].set_title('Ground Truth')\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.suptitle('Restoration Results: Degraded â†’ Restored â†’ Ground Truth', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{PROJECT_ROOT}/restoration_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to Google Drive for later use\n",
    "!cp {config.save_dir}/best_model.pth /content/drive/MyDrive/kintsugi_best_model.pth\n",
    "print(\"Model saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Launch Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Gradio interface\n",
    "import gradio as gr\n",
    "\n",
    "def restore_image(input_image):\n",
    "    \"\"\"Restore an uploaded image.\"\"\"\n",
    "    if input_image is None:\n",
    "        return None\n",
    "    \n",
    "    # Convert to numpy\n",
    "    if isinstance(input_image, Image.Image):\n",
    "        input_image = np.array(input_image)\n",
    "    \n",
    "    # Restore\n",
    "    restored = restorer.restore(input_image, target_size=512)\n",
    "    \n",
    "    return restored\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=restore_image,\n",
    "    inputs=gr.Image(label=\"Upload Damaged Image\"),\n",
    "    outputs=gr.Image(label=\"Restored Image\"),\n",
    "    title=\"ðŸŽŒ Kintsugi AI - Image Restoration\",\n",
    "    description=\"Upload a damaged historical photo and watch AI restore it.\"\n",
    ")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook trained a Kintsugi AI model for image restoration with:\n",
    "\n",
    "- **Architecture:** Attention U-Net with skip connections\n",
    "- **Training:** Self-supervised with synthetic degradation\n",
    "- **Loss:** L1 + SSIM + Perceptual (VGG) + Edge\n",
    "- **Metrics:** Target PSNR > 25dB, SSIM > 0.85\n",
    "\n",
    "For better results:\n",
    "1. Use a larger dataset (CelebA-HQ full, or domain-specific images)\n",
    "2. Train for more epochs (100+)\n",
    "3. Fine-tune on real damaged images if available"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
